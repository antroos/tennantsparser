#!/usr/bin/env python3
"""
–°–∫—Ä–∏–ø—Ç –¥–ª—è –ø–æ–∏—Å–∫–∞ –±–ª–∏–∂–∞–π—à–∏—Ö –∞—É–∫—Ü–∏–æ–Ω–æ–≤ –Ω–∞ Tennants
"""

import requests
from bs4 import BeautifulSoup
import json
from datetime import datetime
import re

class TennantsAuctionFinder:
    def __init__(self):
        self.session = requests.Session()
        self.session.headers.update({
            'User-Agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36',
            'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,*/*;q=0.8',
            'Accept-Language': 'en-US,en;q=0.5',
        })
        
    def find_upcoming_auctions(self):
        """–ü–æ–∏—Å–∫ –ø—Ä–µ–¥—Å—Ç–æ—è—â–∏—Ö –∞—É–∫—Ü–∏–æ–Ω–æ–≤"""
        print("üîç –ò—â–µ–º –±–ª–∏–∂–∞–π—à–∏–µ –∞—É–∫—Ü–∏–æ–Ω—ã –Ω–∞ Tennants...")
        
        # –ü—Ä–æ–±—É–µ–º —Ä–∞–∑–Ω—ã–µ URL
        possible_urls = [
            "https://auctions.tennants.co.uk/",
            "https://auctions.tennants.co.uk/forthcoming-auctions/",
            "https://auctions.tennants.co.uk/live-auctions/",
            "https://auctions.tennants.co.uk/current-auctions/",
            "https://www.tennants.co.uk/auctions/",
            "https://www.tennants.co.uk/"
        ]
        
        for url in possible_urls:
            try:
                print(f"üîç –ü—Ä–æ–±—É–µ–º URL: {url}")
                response = self.session.get(url, timeout=30)
                response.raise_for_status()
                
                soup = BeautifulSoup(response.content, 'html.parser')
                
                auctions = []
                
                # –ò—â–µ–º —Ä–∞–∑–ª–∏—á–Ω—ã–µ —Ç–∏–ø—ã —Å—Å—ã–ª–æ–∫ –Ω–∞ –∞—É–∫—Ü–∏–æ–Ω—ã
                auction_links = []
                
                # –í–∞—Ä–∏–∞–Ω—Ç 1: –ü—Ä—è–º—ã–µ —Å—Å—ã–ª–∫–∏ –Ω–∞ –∞—É–∫—Ü–∏–æ–Ω—ã
                auction_links.extend(soup.find_all('a', href=re.compile(r'/auction/')))
                
                # –í–∞—Ä–∏–∞–Ω—Ç 2: –°—Å—ã–ª–∫–∏ —Å–æ–¥–µ—Ä–∂–∞—â–∏–µ "auction"
                auction_links.extend(soup.find_all('a', href=re.compile(r'auction', re.IGNORECASE)))
                
                print(f"üîó –ù–∞–π–¥–µ–Ω–æ —Å—Å—ã–ª–æ–∫ –Ω–∞ –∞—É–∫—Ü–∏–æ–Ω—ã: {len(auction_links)}")
                
                seen_urls = set()
                
                for link in auction_links:
                    try:
                        auction_url = link.get('href')
                        if not auction_url:
                            continue
                            
                        # –î–µ–ª–∞–µ–º –∞–±—Å–æ–ª—é—Ç–Ω—ã–π URL
                        if auction_url.startswith('/'):
                            base_url = url.rstrip('/')
                            auction_url = base_url + auction_url
                        elif not auction_url.startswith('http'):
                            continue
                        
                        # –ü—Ä–æ–ø—É—Å–∫–∞–µ–º –¥—É–±–ª–∏–∫–∞—Ç—ã
                        if auction_url in seen_urls:
                            continue
                        seen_urls.add(auction_url)
                        
                        # –ü—Ä–æ–≤–µ—Ä—è–µ–º —á—Ç–æ —ç—Ç–æ –¥–µ–π—Å—Ç–≤–∏—Ç–µ–ª—å–Ω–æ —Å—Å—ã–ª–∫–∞ –Ω–∞ –∞—É–∫—Ü–∏–æ–Ω
                        if '/auction/' not in auction_url.lower():
                            continue
                        
                        # –ü–æ–ª—É—á–∞–µ–º –Ω–∞–∑–≤–∞–Ω–∏–µ
                        title = link.get_text(strip=True)
                        if not title or len(title) < 3:
                            continue
                        
                        # –ò—â–µ–º –¥–∞—Ç—É –≤ —Ç–µ–∫—Å—Ç–µ —Ä—è–¥–æ–º —Å —Å—Å—ã–ª–∫–æ–π
                        parent = link.parent
                        date_text = ""
                        if parent:
                            parent_text = parent.get_text()
                            date_match = re.search(r'\d{1,2}[^\w]+\w+[^\w]+20\d{2}', parent_text)
                            if date_match:
                                date_text = date_match.group()
                        
                        # –ò–∑–≤–ª–µ–∫–∞–µ–º ID –∞—É–∫—Ü–∏–æ–Ω–∞
                        auction_id = ""
                        id_match = re.search(r'/auction/(\d+)', auction_url)
                        if id_match:
                            auction_id = id_match.group(1)
                        
                        auction_info = {
                            'id': auction_id,
                            'title': title,
                            'date': date_text,
                            'url': auction_url
                        }
                        
                        auctions.append(auction_info)
                        
                    except Exception as e:
                        continue
                
                if auctions:
                    print(f"‚úÖ –ù–∞–π–¥–µ–Ω–æ –∞—É–∫—Ü–∏–æ–Ω–æ–≤ –Ω–∞ {url}: {len(auctions)}")
                    return auctions
                else:
                    print(f"‚ùå –ê—É–∫—Ü–∏–æ–Ω—ã –Ω–µ –Ω–∞–π–¥–µ–Ω—ã –Ω–∞ {url}")
                    
            except Exception as e:
                print(f"‚ùå –û—à–∏–±–∫–∞ –¥–ª—è {url}: {e}")
                continue
        
        print("‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å –Ω–∞–π—Ç–∏ –∞—É–∫—Ü–∏–æ–Ω—ã –Ω–∏ –Ω–∞ –æ–¥–Ω–æ–º –∏–∑ URLs")
        return []
    
    def get_auction_lots(self, auction_url, limit=5):
        """–ü–æ–ª—É—á–µ–Ω–∏–µ –ª–æ—Ç–æ–≤ –∏–∑ –∞—É–∫—Ü–∏–æ–Ω–∞"""
        print(f"\nüì¶ –ü–æ–ª—É—á–∞–µ–º –ª–æ—Ç—ã –∏–∑ –∞—É–∫—Ü–∏–æ–Ω–∞: {auction_url}")
        
        try:
            response = self.session.get(auction_url, timeout=30)
            response.raise_for_status()
            
            soup = BeautifulSoup(response.content, 'html.parser')
            
            lots = []
            
            # –ò—â–µ–º —Å—Å—ã–ª–∫–∏ –Ω–∞ –ª–æ—Ç—ã
            lot_links = soup.find_all('a', href=re.compile(r'/auction/lot/'))
            
            print(f"üîó –ù–∞–π–¥–µ–Ω–æ —Å—Å—ã–ª–æ–∫ –Ω–∞ –ª–æ—Ç—ã: {len(lot_links)}")
            
            for link in lot_links[:limit]:
                lot_url = link.get('href')
                if not lot_url.startswith('http'):
                    lot_url = 'https://auctions.tennants.co.uk' + lot_url
                
                # –ò–∑–≤–ª–µ–∫–∞–µ–º –Ω–æ–º–µ—Ä –ª–æ—Ç–∞
                lot_match = re.search(r'lot=(\d+)', lot_url)
                lot_id = lot_match.group(1) if lot_match else ""
                
                # –ü–æ–ª—É—á–∞–µ–º —Ç–µ–∫—Å—Ç –ª–æ—Ç–∞
                lot_text = link.get_text(strip=True)
                
                lot_info = {
                    'id': lot_id,
                    'text': lot_text,
                    'url': lot_url
                }
                
                lots.append(lot_info)
            
            return lots
            
        except Exception as e:
            print(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –ø–æ–ª—É—á–µ–Ω–∏–∏ –ª–æ—Ç–æ–≤: {e}")
            return []

def main():
    finder = TennantsAuctionFinder()
    
    # –ù–∞—Ö–æ–¥–∏–º –∞—É–∫—Ü–∏–æ–Ω—ã
    auctions = finder.find_upcoming_auctions()
    
    if not auctions:
        print("‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å –Ω–∞–π—Ç–∏ –∞—É–∫—Ü–∏–æ–Ω—ã")
        return
    
    print("\nüéØ –ù–ê–ô–î–ï–ù–ù–´–ï –ê–£–ö–¶–ò–û–ù–´:")
    print("="*60)
    
    for i, auction in enumerate(auctions[:10], 1):
        print(f"{i}. {auction['title']}")
        print(f"   ID: {auction['id']}")
        print(f"   –î–∞—Ç–∞: {auction['date']}")
        print(f"   URL: {auction['url']}")
        print()
    
    # –ë–µ—Ä–µ–º –ø–µ—Ä–≤—ã–π –∞—É–∫—Ü–∏–æ–Ω –¥–ª—è —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è
    if auctions:
        test_auction = auctions[0]
        print(f"üéØ –¢–ï–°–¢–ò–†–£–ï–ú –ù–ê –ê–£–ö–¶–ò–û–ù–ï: {test_auction['title']}")
        print("="*60)
        
        # –ü–æ–ª—É—á–∞–µ–º –ª–æ—Ç—ã
        lots = finder.get_auction_lots(test_auction['url'])
        
        if lots:
            print(f"\nüì¶ –ù–ê–ô–î–ï–ù–ù–´–ï –õ–û–¢–´ (–ø–µ—Ä–≤—ã–µ 5):")
            print("="*40)
            
            for i, lot in enumerate(lots, 1):
                print(f"{i}. –õ–æ—Ç ID: {lot['id']}")
                print(f"   –¢–µ–∫—Å—Ç: {lot['text'][:100]}...")
                print(f"   URL: {lot['url']}")
                print()
            
            # –í–æ–∑–≤—Ä–∞—â–∞–µ–º –ø–µ—Ä–≤—ã–π –ª–æ—Ç –¥–ª—è —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è
            if lots:
                print(f"‚úÖ –†–ï–ö–û–ú–ï–ù–î–£–ï–ú–´–ô –õ–û–¢ –î–õ–Ø –¢–ï–°–¢–ò–†–û–í–ê–ù–ò–Ø:")
                print(f"URL: {lots[0]['url']}")
                return lots[0]['url']
        else:
            print("‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å –Ω–∞–π—Ç–∏ –ª–æ—Ç—ã –≤ –∞—É–∫—Ü–∏–æ–Ω–µ")
    
    return None

if __name__ == "__main__":
    main() 